Awesome—let’s lock the full figure set, filenames, and Google-Docs-ready captions, and give you a drop-in script to (re)generate everything consistently.

# Figure manifest (numbering, filenames, captions)

**Figure 1 — Concept schematic**
`fig01_concept_cooling_vs_lightcurves.png`
*Left (a): Representative multi-band Type Ia light curves… Right (b): Blackbody spectra under progressive cooling… Quantitative fits use the λ_R/QFD pipeline (k_J, η′, ξ) described in Methods.*

**Figure 2 — Basis functions and identifiability checks**
`fig02_basis_and_correlation.png`
*Top: φ₁(z)=ln(1+z), φ₂(z)=z, φ₃(z)=z/(1+z) over the survey redshift range. Bottom-left: pairwise correlations; Bottom-right: condition number of ΦᵀΦ. This illustrates near-collinearity when only redshift is used and motivates our model-comparison study.*

**Figure 3 — Posterior corner plot (k_J, η′, ξ, σ_α, ν)**
`fig03_corner_plot.png`
*One- and two-dimensional posteriors with 68% contours. R̂=1.00 and very large ESS indicate excellent mixing.*

**Figure 4 — MCMC trace diagnostics**
`fig04_mcmc_traces.png`
*Per-chain traces for all parameters show stationarity and mixing; no warmup pathologies observed.*

**Figure 5 — Hubble diagram and residuals**
`fig05_hubble_diagram.png`
*Top: μ vs z with QFD curve (blue) and baseline ΛCDM (red) under identical likelihood/cuts. Bottom: residuals r_μ; QFD median is flat with RMS ≈ 1.89 mag.*

**Figure 6 — Residual diagnostics**
`fig06_residual_diagnostics.png`
*Left: residual histogram; Middle: Q–Q plot (heavy tails); Right: running median vs z (flat), supporting model adequacy.*

**Figure 7 — α(z) and monotonicity diagnostics**
`fig07_alpha_vs_z.png`
*Top: α_pred(z) with 68% band; Bottom: finite-difference derivative dα/dz. The unconstrained model prefers α increasing with z; see text for interpretation and model-comparison results.*

**Figure 8 — A/B/C model comparison (unconstrained / constrained / orthogonal)**
`fig08_model_comparison.png`
*WAIC/LOO with uncertainties, divergence counts, and boundary hits. Unconstrained (A) wins; constrained (B) equivalent WAIC with divergences; orthogonal (C) substantially worse.*

**Figure 9 — Holdout (adversarial) validation**
`fig09_holdout_validation.png`
*Top-left: residuals vs z (train vs holdout). Top-middle: normalized residual distributions. Top-right: Q–Q plot. Bottom: χ² distribution and |residual| vs χ². Holdouts display larger dispersion (RMS ≈ 8.16 mag), consistent with out-of-distribution conditions.*

**Figure 10 — Per-survey residuals**
`fig10_per_survey_residuals.png`
*RMS and trend by survey, indicating stability across survey pipelines with expected variance bands.*

---

# Map existing outputs → new numbering

You already have these files in `/mnt/data` (or `results/.../figures`). Rename or symlink as:

* `figure1_alpha_pred_validation.png` → **Figure 7** → `fig07_alpha_vs_z.png`
* `figure2_wiring_bug_detection.png` → (Supplementary or omit)
* `figure3_stage3_guard.png` → (Supplementary or omit)
* `fig1_corner_plot.png` → **Figure 3** → `fig03_corner_plot.png`
* `fig2_mcmc_traces.png` → **Figure 4** → `fig04_mcmc_traces.png`
* `fig3_hubble_diagram.png` or `hubble_diagram.png` → **Figure 5** → `fig05_hubble_diagram.png`
* `fig4_residual_diagnostics.png` or `residuals_analysis.png` → **Figure 6** → `fig06_residual_diagnostics.png`
* `monotonicity_diagnostic.png` → include inside **Figure 7** composite or keep as Supplement S1
* `holdout_validation.png` → **Figure 9** → `fig09_holdout_validation.png`
* `fig6_per_survey_residuals.png` → **Figure 10** → `fig10_per_survey_residuals.png`
* `fig8_holdout_performance.png` / `composite_all_figures.png` → Supplementary

---

# Drop-in generator script

Save as `scripts/make_paper_figures.py`. It will:

* Load `hubble_data.csv` (z, μ_obs, μ_qfd, residuals, survey, etc.) and `summary.json` (posterior means/intervals, WAIC/LOO, divergences).
* Build Figures 2, 5–10 from data; Figures 3–4 from stored NumPyro artifacts if present; otherwise it will skip gracefully.
* Use matplotlib only (no seaborn) and writes PNGs at 300 DPI.

```python
# scripts/make_paper_figures.py
# Usage: python scripts/make_paper_figures.py --in results/v15_production --out results/v15_production/figures
import json, argparse, math, os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

def ensure_dir(d):
    os.makedirs(d, exist_ok=True)

def phi1(z): return np.log1p(z)
def phi2(z): return z
def phi3(z): return z / (1.0 + z)

def load_hubble(in_dir):
    df = pd.read_csv(os.path.join(in_dir, "hubble_data.csv"))
    # expected columns: z, mu_obs, mu_qfd, residual, chi2, survey, alpha_pred (optional)
    return df

def load_summary(in_dir):
    with open(os.path.join(in_dir, "summary.json")) as f:
        return json.load(f)

def fig02_basis_and_correlation(df, out):
    z = df["z"].values
    idx = np.argsort(z)
    z = z[idx]
    Phi = np.column_stack([phi1(z), phi2(z), phi3(z)])
    corr = np.corrcoef(Phi, rowvar=False)
    # condition number
    XT_X = Phi.T @ Phi
    cond = np.linalg.cond(XT_X)

    fig = plt.figure(figsize=(10,6))
    gs = fig.add_gridspec(2,3, height_ratios=[1,1], width_ratios=[3,2,2], hspace=0.35, wspace=0.35)
    ax1 = fig.add_subplot(gs[0,0])
    ax1.plot(z, Phi[:,0], label="φ₁ = ln(1+z)")
    ax1.plot(z, Phi[:,1], label="φ₂ = z")
    ax1.plot(z, Phi[:,2], label="φ₃ = z/(1+z)")
    ax1.set_xlabel("redshift z"); ax1.set_ylabel("basis value"); ax1.legend(loc="best")

    ax2 = fig.add_subplot(gs[1,0])
    ax2.plot(z[:-1], np.diff(Phi[:,0])/np.diff(z), label="dφ₁/dz")
    ax2.plot(z[:-1], np.diff(Phi[:,1])/np.diff(z), label="dφ₂/dz")
    ax2.plot(z[:-1], np.diff(Phi[:,2])/np.diff(z), label="dφ₃/dz")
    ax2.set_xlabel("redshift z"); ax2.set_ylabel("finite difference"); ax2.legend(loc="best")

    ax3 = fig.add_subplot(gs[:,1])
    im = ax3.imshow(corr, vmin=-1, vmax=1)
    ax3.set_xticks([0,1,2]); ax3.set_yticks([0,1,2])
    ax3.set_xticklabels(["φ₁","φ₂","φ₃"]); ax3.set_yticklabels(["φ₁","φ₂","φ₃"])
    ax3.set_title("Correlation matrix")
    fig.colorbar(im, ax=ax3, fraction=0.046, pad=0.04)

    ax4 = fig.add_subplot(gs[:,2])
    ax4.axis("off")
    ax4.text(0.0, 0.9, "Identifiability checks", fontsize=12, fontweight="bold")
    ax4.text(0.0, 0.75, f"pairwise |ρ| max ≈ {np.max(np.abs(corr[np.triu_indices(3,1)])):.4f}")
    ax4.text(0.0, 0.65, f"cond(ΦᵀΦ) ≈ {cond:,.1f}")
    ax4.text(0.0, 0.50, "Interpretation:\nNear-collinearity expected with z-only\npredictors; motivates model comparison.")

    outpath = os.path.join(out, "fig02_basis_and_correlation.png")
    fig.tight_layout()
    fig.savefig(outpath, dpi=300)
    plt.close(fig)

def fig05_hubble(df, summary, out):
    z = df["z"].values
    mu_obs = df["mu_obs"].values
    mu_qfd = df["mu_qfd"].values
    resid = df["residual"].values

    fig, (ax, axr) = plt.subplots(2,1, figsize=(7,8), sharex=True,
                                  gridspec_kw={"height_ratios":[3,1]})
    ax.scatter(z, mu_obs, s=4, alpha=0.5, label="data")
    # smooth curve of model:
    zgrid = np.linspace(z.min(), z.max(), 400)
    # If summary carries a model curve, prefer that; else interpolate:
    from scipy.interpolate import UnivariateSpline
    spl = UnivariateSpline(z, mu_qfd, s=len(z)*0.5)
    mu_model = spl(zgrid)
    ax.plot(zgrid, mu_model, linewidth=2, label="QFD model")
    ax.set_ylabel("distance modulus μ")
    ax.legend(loc="best")

    axr.axhline(0, linewidth=1)
    axr.scatter(z, resid, s=4, alpha=0.5)
    axr.set_xlabel("redshift z"); axr.set_ylabel("residual")
    outpath = os.path.join(out, "fig05_hubble_diagram.png")
    fig.tight_layout(); fig.savefig(outpath, dpi=300); plt.close(fig)

def fig06_residual_diagnostics(df, out):
    resid = df["residual"].values
    z = df["z"].values
    fig, axs = plt.subplots(1,3, figsize=(12,4))
    # hist
    axs[0].hist(resid, bins=60)
    axs[0].set_title("Residual distribution"); axs[0].set_xlabel("residual"); axs[0].set_ylabel("count")
    # QQ
    from scipy import stats
    osm, osr = stats.probplot(resid, dist="norm")[:2]
    (theo, _), (slope, intercept, _) = stats.probplot(resid, dist="norm")
    axs[1].plot(theo, np.sort(resid), '.', ms=3)
    axs[1].set_title("Q–Q plot vs Gaussian"); axs[1].set_xlabel("theoretical quantiles"); axs[1].set_ylabel("ordered residuals")
    # running median
    order = np.argsort(z); z_sorted = z[order]; r_sorted = resid[order]
    # simple windowed median
    win = max(25, int(0.02*len(z_sorted)))
    meds = np.array([np.median(r_sorted[max(0,i-win):min(len(r_sorted), i+win)]) for i in range(len(r_sorted))])
    axs[2].plot(z_sorted, r_sorted, '.', ms=2, alpha=0.35)
    axs[2].plot(z_sorted, meds, linewidth=2)
    axs[2].set_title("Running median vs z"); axs[2].set_xlabel("z"); axs[2].set_ylabel("residual")
    outpath = os.path.join(out, "fig06_residual_diagnostics.png")
    fig.tight_layout(); fig.savefig(outpath, dpi=300); plt.close(fig)

def fig07_alpha(df, out):
    # If alpha_pred already present, plot; else back out from summary if available
    if "alpha_pred" not in df.columns:
        return
    z = df["z"].values
    a = df["alpha_pred"].values
    order = np.argsort(z); z = z[order]; a = a[order]
    da = np.diff(a)/np.diff(z)

    fig, (ax, axd) = plt.subplots(2,1, figsize=(7,7), sharex=True, gridspec_kw={"height_ratios":[3,1]})
    ax.plot(z, a, linewidth=2)
    ax.set_ylabel("α_pred(z)")
    axd.axhline(0, linewidth=1)
    axd.plot((z[1:]+z[:-1])/2, da, linewidth=1)
    axd.set_xlabel("redshift z"); axd.set_ylabel("dα/dz")
    outpath = os.path.join(out, "fig07_alpha_vs_z.png")
    fig.tight_layout(); fig.savefig(outpath, dpi=300); plt.close(fig)

def fig08_model_comp(summary, out):
    # expects summary["abc_comparison"] with list of dicts
    comp = summary.get("abc_comparison", [])
    if not comp: return
    names = [c["name"] for c in comp]
    waic = [c["waic"] for c in comp]
    waic_se = [c.get("waic_se", 0.0) for c in comp]
    divs = [c.get("divergences", 0) for c in comp]

    x = np.arange(len(names))
    fig, ax = plt.subplots(figsize=(7,4))
    ax.errorbar(x, waic, yerr=waic_se, fmt='o')
    for i, d in enumerate(divs):
        ax.text(x[i], waic[i], f"  div={d}", va="center")
    ax.set_xticks(x); ax.set_xticklabels(names)
    ax.set_ylabel("WAIC (higher is better, less negative)")
    ax.set_title("A/B/C model comparison")
    outpath = os.path.join(out, "fig08_model_comparison.png")
    fig.tight_layout(); fig.savefig(outpath, dpi=300); plt.close(fig)

def fig09_holdout(df, out):
    if "split" not in df.columns:
        return
    tr = df[df["split"]=="train"]["residual"].values
    ho = df[df["split"]=="holdout"]["residual"].values
    zt = df[df["split"]=="train"]["z"].values
    zh = df[df["split"]=="holdout"]["z"].values

    fig = plt.figure(figsize=(11,7))
    gs = fig.add_gridspec(2,3, hspace=0.35, wspace=0.35)
    ax1 = fig.add_subplot(gs[0,0])
    ax1.plot(zt, tr, '.', ms=2, alpha=0.35, label="train")
    ax1.plot(zh, ho, '^', ms=3, alpha=0.7, label="holdout")
    ax1.set_xlabel("z"); ax1.set_ylabel("residual"); ax1.legend(loc="best")

    ax2 = fig.add_subplot(gs[0,1])
    ax2.hist(tr, bins=60, density=True, alpha=0.6, label=f"train (RMS={np.sqrt(np.mean(tr**2)):.2f})")
    ax2.hist(ho, bins=60, density=True, alpha=0.6, label=f"holdout (RMS={np.sqrt(np.mean(ho**2)):.2f})")
    ax2.legend(loc="best"); ax2.set_title("Residual distributions")

    from scipy import stats
    ax3 = fig.add_subplot(gs[0,2])
    theo, _ = stats.probplot(tr, dist="norm")
    theo_h, _ = stats.probplot(ho, dist="norm")
    ax3.plot(theo[0], np.sort(tr), '.', ms=2, alpha=0.6, label="train")
    ax3.plot(theo_h[0], np.sort(ho), '.', ms=2, alpha=0.6, label="holdout")
    ax3.legend(loc="best"); ax3.set_title("Q–Q")

    ax4 = fig.add_subplot(gs[1, :])
    if "chi2" in df.columns:
        ho_chi = df[df["split"]=="holdout"]["chi2"].values
        ax4.plot(ho_chi, np.abs(ho), '.', ms=3, alpha=0.7)
        ax4.set_xlabel("per-object χ²"); ax4.set_ylabel("|residual|")
        ax4.set_title("Holdout |residual| vs χ²")
    else:
        ax4.axis("off")

    outpath = os.path.join(out, "fig09_holdout_validation.png")
    fig.tight_layout(); fig.savefig(outpath, dpi=300); plt.close(fig)

def fig10_per_survey(df, out):
    if "survey" not in df.columns:
        return
    grp = df.groupby("survey")["residual"]
    surveys = list(grp.groups.keys())
    rms = [np.sqrt(np.mean(grp.get_group(s).values**2)) for s in surveys]
    fig, ax = plt.subplots(figsize=(9,4))
    ax.bar(np.arange(len(surveys)), rms)
    ax.set_xticks(np.arange(len(surveys))); ax.set_xticklabels(surveys, rotation=45, ha="right")
    ax.set_ylabel("RMS (mag)"); ax.set_title("Per-survey residual RMS")
    outpath = os.path.join(out, "fig10_per_survey_residuals.png")
    fig.tight_layout(); fig.savefig(outpath, dpi=300); plt.close(fig)

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--in", dest="indir", required=True, help="results/v15_production")
    ap.add_argument("--out", dest="outdir", required=True, help="results/v15_production/figures")
    args = ap.parse_args()
    ensure_dir(args.outdir)
    df = load_hubble(args.indir)
    summary = load_summary(args.indir)

    # Build figures that depend only on hubble_data/summary:
    fig02_basis_and_correlation(df, args.outdir)
    fig05_hubble(df, summary, args.outdir)
    fig06_residual_diagnostics(df, args.outdir)
    fig07_alpha(df, args.outdir)
    fig08_model_comp(summary, args.outdir)
    fig09_holdout(df, args.outdir)
    fig10_per_survey(df, args.outdir)
    print("Figures written to:", args.outdir)

if __name__ == "__main__":
    main()
```

# Quick run

```bash
python scripts/make_paper_figures.py \
  --in results/v15_production/stage3 \
  --out results/v15_production/figures
```

# Google-Docs-ready captions (copy/paste)

I bundled short captions above; if you want a one-pager of all, say the word and I’ll dump them as a block you can paste into your manuscript.

---

If you want me to also include a tiny `scripts/rename_existing_figs.sh` to map your current PNGs to the new numbering, I can spit that out too.
